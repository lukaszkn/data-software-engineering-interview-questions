# Apache Superset
Apache Superset

* [Can you create custom SQL functions or macros in Superset](#Can-you-create-custom-SQL-functions-or-macros-in-Superset)
* [What databases does Superset support](#What-databases-does-Superset-support)
* [What are the different visualization types available in Superset](#What-are-the-different-visualization-types-available-in-Superset)
* [What is Superset's "Explore" feature](#What-is-Superset-s-Explore-feature)
* [How can you create interactive filters in Superset](#How-can-you-create-interactive-filters-in-Superset)
* [What are some security considerations when using Superset in a production environment](#What-are-some-security-considerations-when-using-Superset-in-a-production-environment)
* [Can you create custom visualizations in Superset](#Can-you-create-custom-visualizations-in-Superset)
* [What is the Superset Database Metadata Model](#What-is-the-Superset-Database-Metadata-Model)
* [How does Superset handle data lineage in complex data pipelines](#How-does-Superset-handle-data-lineage-in-complex-data-pipelines)
* [Can Superset connect to data lakes or distributed file systems](#Can-Superset-connect-to-data-lakes-or-distributed-file-systems)
* [What are the advantages of using SQL Lab in Superset](#What-are-the-advantages-of-using-SQL-Lab-in-Superset)
* [Can Superset handle data from multiple databases or data sources within the same dashboard](#Can-Superset-handle-data-from-multiple-databases-or-data-sources-within-the-same-dashboard)
* [Can you share dashboards with other users in Superset](#Can-you-share-dashboards-with-other-users-in-Superset)
* [Can you schedule and automate reports in Superset](#Can-you-schedule-and-automate-reports-in-Superset)
* [What are the key components of Superset](#What-are-the-key-components-of-Superset)
* [What is SQL Lab in Superset](#What-is-SQL-Lab-in-Superset)
* [Can Superset connect to cloud-based data warehouses like Amazon Redshift or Google BigQuery](#Can-Superset-connect-to-cloud-based-data-warehouses-like-Amazon-Redshift-or-Google-BigQuery)
* [What is Superset's support for dashboard interactivity and filtering](#What-is-Superset-s-support-for-dashboard-interactivity-and-filtering)
* [What is the purpose of the Superset configuration file](#What-is-the-purpose-of-the-Superset-configuration-file)
* [How does Superset handle data caching for queries with dynamic parameters](#How-does-Superset-handle-data-caching-for-queries-with-dynamic-parameters)
* [What is Superset's support for anomaly detection](#What-is-Superset-s-support-for-anomaly-detection)
* [What is the Superset SQL Lab Query History feature](#What-is-the-Superset-SQL-Lab-Query-History-feature)
* [Can Superset connect to streaming data sources](#Can-Superset-connect-to-streaming-data-sources)
* [Does Superset support embedding dashboards in other applications](#Does-Superset-support-embedding-dashboards-in-other-applications)
* [Can Superset be used for real-time data streaming analytics](#Can-Superset-be-used-for-real-time-data-streaming-analytics)
* [What is Apache Superset](#What-is-Apache-Superset)
* [What is a dashboard in Superset](#What-is-a-dashboard-in-Superset)
* [What is the role of metadata databases in Superset](#What-is-the-role-of-metadata-databases-in-Superset)
* [What are Superset's alerting capabilities](#What-are-Superset-s-alerting-capabilities)
* [Can Superset connect to NoSQL databases](#Can-Superset-connect-to-NoSQL-databases)
* [Does Superset support cross-database joins in SQL queries](#Does-Superset-support-cross-database-joins-in-SQL-queries)
* [Can you explain the process of connecting a database to Superset](#Can-you-explain-the-process-of-connecting-a-database-to-Superset)
* [What is Superset's data caching mechanism](#What-is-Superset-s-data-caching-mechanism)
* [Can you create drill-down or drill-through reports in Superset](#Can-you-create-drill-down-or-drill-through-reports-in-Superset)
* [How can you create a new dashboard in Superset](#How-can-you-create-a-new-dashboard-in-Superset)
* [What is Superset's SQL Lab Ad-Hoc Editor](#What-is-Superset-s-SQL-Lab-Ad-Hoc-Editor)
* [How can you customize the look and feel of Superset's visualizations and dashboards](#How-can-you-customize-the-look-and-feel-of-Superset-s-visualizations-and-dashboards)
* [Which programming language is Superset primarily built with](#Which-programming-language-is-Superset-primarily-built-with)
* [How does Superset handle data lineage and data governance](#How-does-Superset-handle-data-lineage-and-data-governance)
* [Does Superset support data exploration using natural language queries (NLQ)](#Does-Superset-support-data-exploration-using-natural-language-queries-NLQ)
* [How can you secure Superset](#How-can-you-secure-Superset)
* [Can you define metrics and dimensions in Superset](#Can-you-define-metrics-and-dimensions-in-Superset)
* [What is Superset's support for data permissions and data masking](#What-is-Superset-s-support-for-data-permissions-and-data-masking)
* [What is a slice in Superset](#What-is-a-slice-in-Superset)
* [What is Superset's support for row-level security (RLS)](#What-is-Superset-s-support-for-row-level-security-RLS)
* [How can you extend Superset's functionality](#How-can-you-extend-Superset-s-functionality)
* [What is Superset's approach to data caching and cache invalidation](#What-is-Superset-s-approach-to-data-caching-and-cache-invalidation)
* [How can you install Superset](#How-can-you-install-Superset)
* [Can you deploy Superset in a distributed environment](#Can-you-deploy-Superset-in-a-distributed-environment)
* [Does Superset support multi-tenancy](#Does-Superset-support-multi-tenancy)
* [What are some common security best practices for deploying Superset](#What-are-some-common-security-best-practices-for-deploying-Superset)
* [What is Superset's support for time-zone conversions in visualizations](#What-is-Superset-s-support-for-time-zone-conversions-in-visualizations)
* [How can you monitor the performance of Superset](#How-can-you-monitor-the-performance-of-Superset)
* [What is Superset's support for data exploration on streaming data sources](#What-is-Superset-s-support-for-data-exploration-on-streaming-data-sources)
* [Does Superset support geospatial data visualization](#Does-Superset-support-geospatial-data-visualization)
* [Can you integrate Superset with other BI tools or data platforms](#Can-you-integrate-Superset-with-other-BI-tools-or-data-platforms)
* [Can you integrate Superset with external authentication systems](#Can-you-integrate-Superset-with-external-authentication-systems)
* [What is Druid in the context of Superset](#What-is-Druid-in-the-context-of-Superset)
* [What is Superset's support for user-defined functions (UDFs)](#What-is-Superset-s-support-for-user-defined-functions-UDFs)
* [Does Superset support data lineage across multiple dashboards and slices](#Does-Superset-support-data-lineage-across-multiple-dashboards-and-slices)
* [What are some ways to optimize query performance in Superset](#What-are-some-ways-to-optimize-query-performance-in-Superset)
* [What is Superset's support for time-series data analysis](#What-is-Superset-s-support-for-time-series-data-analysis)
* [Can Superset integrate with external data catalog systems](#Can-Superset-integrate-with-external-data-catalog-systems)
* [How does Superset handle large datasets](#How-does-Superset-handle-large-datasets)
* [What is Superset's support for data access logging and auditing](#What-is-Superset-s-support-for-data-access-logging-and-auditing)
* [How does Superset handle data security and access control](#How-does-Superset-handle-data-security-and-access-control)
* [What is Superset's integration with Apache Airflow](#What-is-Superset-s-integration-with-Apache-Airflow)
* [What is Superset's support for data storytelling and annotations](#What-is-Superset-s-support-for-data-storytelling-and-annotations)
* [Does Superset provide data lineage tracking](#Does-Superset-provide-data-lineage-tracking)
* [Can Superset handle real-time data processing and visualization](#Can-Superset-handle-real-time-data-processing-and-visualization)
* [Can you integrate Superset with version control systems](#Can-you-integrate-Superset-with-version-control-systems)
* [How does Superset differ from other BI tools](#How-does-Superset-differ-from-other-BI-tools)
* [How can you create a new slice in Superset](#How-can-you-create-a-new-slice-in-Superset)

## Can you create custom SQL functions or macros in Superset
You cannot define custom SQL functions or create macros directly within Apache Superset itself. Superset serves as a visualization and dashboard tool that connects to underlying databases, and relies on the database engine's SQL capabilities.

However, you can:

- **Use SQL Lab to write arbitrary SQL queries:** In SQL Lab, you can write complex SQL, including calls to any custom SQL functions or macros that are already defined in your database.
- **Leverage database-side functions/macros:** If your database supports user-defined functions (UDFs), stored procedures, or macros (like in Snowflake, BigQuery, etc.), you can create them in the database and call them from Superset queries.
- **Templating (Jinja):** In some SQL contexts (like virtual datasets), Superset supports limited use of Jinja templating, which can act like lightweight macros (e.g., `{{ filter values('col') }}` to make queries dynamic). This is not full macro capability, but can help parameterize queries.

To summarize: actual function and macro definitions must be done in the underlying database, and Superset consumes them by invoking them in your SQL queries. Superset itself does not store or manage custom SQL functions or macros internally.

[Top](#top)

## What databases does Superset support
Apache Superset supports a wide range of SQL-speaking databases via SQLAlchemy drivers. Out of the box, it is compatible with:

- **Popular Relational Databases:**  
  - PostgreSQL  
  - MySQL/MariaDB  
  - Oracle  
  - Microsoft SQL Server  
  - SQLite

- **Cloud Databases & Data Warehouses:**  
  - Google BigQuery  
  - Amazon Redshift  
  - Snowflake  
  - Amazon Athena  
  - Apache Druid  
  - Presto/Trino  
  - ClickHouse

- **Others:**  
  - Apache Hive  
  - Apache Impala  
  - Firebolt  
  - Vertica  
  - Databricks (using SQL endpoints)

Support for additional databases can be added as long as a compatible SQLAlchemy dialect is available. The flexibility comes from Superset’s reliance on SQLAlchemy's extensible connection mechanism. No native support exists for NoSQL databases unless they provide a SQL interface accessible via a SQLAlchemy dialect.

[Top](#top)

## What are the different visualization types available in Superset
Apache Superset offers a broad range of visualization types to help users explore and present data insights. The main visualization types available include:

- **Table:** Basic tabular view of data.
- **Pivot Table:** Multi-dimensional data summarization and analysis.
- **Big Number:** Displays a single aggregate metric, optionally with trend lines.
- **Big Number with Trendline:** Shows a big metric and visualizes its change over time.
- **Time-series Chart:** Multiple subtypes, including line, bar, and area charts for trends over time.
- **Bar Chart:** Horizontal or vertical representation for comparing quantities.
- **Pie Chart:** Proportional representation of categories as slices of a circle.
- **Donut Chart:** Similar to a pie chart but with a hollow center.
- **Gauge Chart:** Shows progress toward a goal or threshold.
- **Scatter Plot:** Visualization of data distribution or correlations using points in a Cartesian plane.
- **Bubble Chart:** Enhanced scatter plot with variable point sizes.
- **Heatmap:** Color-coded matrix representing values across two axes.
- **Calendar Heatmap:** Displays activities or values on a calendar grid.
- **Sankey Diagram:** Visualization of flows and connections between categories.
- **Sunburst Diagram:** Hierarchical data using concentric circles.
- **Treemap:** Hierarchical data using nested rectangles.
- **Box Plot:** Displays the distribution and identifies outliers.
- **Histogram:** Distribution of numerical data using bins.
- **Area Chart:** Variation of the line chart with filled areas.
- **Word Cloud:** Highlights word frequency with size variation.
- **Map Visualizations:**
  - **Deck.gl:** Geospatial charts like Scatter plots, Hex bins, Grid, Arc, and Path overlays.
  - **Country Map/Choropleth:** Color-coded regions based on aggregated values.
- **Network Graph:** Nodes and edges to represent relationships.

Superset also supports custom plugin visualizations, enabling users to build or add new chart types as needed. The list may evolve, as Superset continuously adds new visualization types and enhancements through its plugin architecture.

[Top](#top)

## What is Superset's "Explore" feature
Superset's "Explore" feature allows users to visually create and customize data visualizations without writing code. In the Explore interface, you can select a dataset, choose the visualization type (such as bar chart, time series, table, etc.), and configure metrics, dimensions, filters, groupings, and formatting options. The feature provides a drag-and-drop UI for assembling visuals, running queries in real-time, and instantly previewing results. "Explore" is designed for ad hoc data exploration, enabling users to iterate quickly, experiment with different cuts of data, and generate insights interactively. Once satisfied, users can save their visualizations as charts or add them to dashboards.

[Top](#top)

## How can you create interactive filters in Superset
In Apache Superset, interactive filters are created primarily using Filter Box or Dashboard Filter components. Here’s how you can create and use interactive filters:

1. **Using Filter Box Chart:**
   - In the Superset Explore interface, select the “Filter Box” visualization type.
   - Choose a dataset, and add one or more fields to the Filters panel. These become the filter options users can select.
   - Configure additional options like Default Value or whether multiple selections are allowed.
   - Save this chart.

2. **Adding Filters to Dashboards:**
   - Add your Filter Box component to a dashboard.
   - Link the Filter Box to target charts by editing each chart, going to the “Filters” section, and specifying which filter fields from the Filter Box should be applied.

3. **Native Filters (recommended from Superset 1.0+):**
   - In dashboard edit mode, click on “Filters” in the right-side panel and add a new filter.
   - Choose the dataset and the field you want to filter on (e.g., Country, Date, Category).
   - Configure filter display options (dropdown, time slider, etc.), and whether it should apply globally or to specific charts.
   - Assign the filter to one or more charts on the dashboard.
   - Multiple native filters can be used, including time filters and cascading filters (where the selection in one filter narrows options in another).

4. **Cross-filtering (as of recent versions):**
   - Enable cross-filtering so that interacting with one chart (e.g., clicking a bar in a bar chart) dynamically filters other charts according to that selection.

**Summary:**
- Native Filters (dashboard-level filters) provide the most flexibility and modern features.
- Filter Boxes are legacy, but still supported.
- Filters can be targeted to specific charts or applied to all charts in a dashboard.
- Interactive controls allow users to slice and dice the data in real time.

[Top](#top)

## What are some security considerations when using Superset in a production environment
Some security considerations when using Apache Superset in a production environment include:

1. **Authentication and Authorization**:  
   - Use a strong authentication backend such as LDAP, OAuth, or SAML. Do not rely on the default database authentication for production.
   - Configure role-based access control (RBAC) to restrict user access to only the necessary data sources, dashboards, and slices.

2. **Secure Connections**:  
   - Enable HTTPS for all traffic to and from the Superset server to protect data in transit.
   - Configure the connections to data sources to use encrypted protocols where possible.

3. **Database Credentials Protection**:  
   - Store connection strings and credentials in environment variables or a secure vault, rather than in configuration files or the metadata database.
   - Restrict permissions for the metadata database used by Superset.

4. **SQL Injection Prevention**:  
   - Ensure users do not have access to run arbitrary SQL queries unless strictly necessary.
   - Regularly review permissions and set up explicit controls on who can execute raw SQL.

5. **Secrets Management**:  
   - Do not commit sensitive information (like SECRET_KEY, passwords) to version control.
   - Rotate credentials periodically.

6. **Session Management**:  
   - Set strong session timeout values and secure cookies (`SESSION_COOKIE_SECURE=True`).
   - Use long, unpredictable values for `SECRET_KEY`.

7. **Deployment Hardening**:  
   - Deploy Superset behind a secure reverse proxy (like Nginx) and firewall.
   - Remove or disable the FAB (Flask-AppBuilder) “Public” role.
   - Limit exposure of the Superset UI and APIs to trusted networks or via VPN.

8. **Regular Updates**:  
   - Keep Superset and all dependencies updated to mitigate vulnerabilities.
   - Apply security patches in a timely manner.

9. **Audit Logging**:  
   - Enable and monitor Superset logs for unusual access patterns or privileged actions.
   - Integrate logs with SIEM or other monitoring systems if needed.

10. **Limiting Feature Exposure**:  
    - Disable or restrict the upload of CSVs and other features if not needed, as these can increase the attack surface.

Addressing these considerations helps prevent unauthorized access, data leaks, and accidental privilege escalations in Superset deployments.

[Top](#top)

## Can you create custom visualizations in Superset
Yes, you can create custom visualizations in Apache Superset. Superset's architecture supports extensibility through a plugin system. Custom visualizations are typically developed as JavaScript plugins using the Superset Plugin Chart API, which is built on top of React and Apache ECharts. Developers can create custom chart types by creating new plugins, packaging them, and registering them with the Superset frontend.

After building and registering the plugin, the new visualization type becomes available in the chart creation interface. This approach requires knowledge of JavaScript (especially React) and familiarity with the Superset frontend build process. Additionally, open-source community plugins and contributed charts can also be integrated to extend visualization options without building them from scratch.

[Top](#top)

## What is the Superset Database Metadata Model
The Superset Database Metadata Model refers to how Apache Superset internally represents, manages, and stores information about connected databases, their schemas, tables, columns, metrics, and related metadata. Superset does not store the original data but maintains metadata about data sources for the purposes of visualization, querying, and security.

Key components of the Superset metadata model include:

- **Database**: Each record represents a database connection. Metadata such as the SQLAlchemy connection URI, backend engine (MySQL, PostgreSQL, Oracle, etc.), and connection parameters are stored.

- **Table** (now often referred to as "Dataset"): Represents a logical data source available for visualization. This can be a physical table or view, or a virtual dataset defined by a SQL query. Metadata includes table name, schema, associated database, and configuration flags (such as filter selectivity settings).

- **Columns**: Metadata for columns within a dataset, including name, type (string, integer, datetime, etc.), verbose name, whether the column can be used for filtering, and any supporting comments or descriptions.

- **Metrics**: Aggregations or calculations defined on datasets; includes metric expressions, type (sum, avg, count, custom SQL etc.), and labels.

- **SQL Lab & Saved Queries**: Superset stores metadata about ad hoc SQL queries executed by users, their status, and related context.

- **Other entities**: Superset's metadata database also contains models for charts, dashboards, user access permissions, saved filters, annotations, and tagging.

All of this metadata is stored in Superset's own metadata database, which uses a relational database backend (like PostgreSQL, MySQL, or SQLite). Data in this database enables Superset’s UI to surface available data sources, suggest columns, build queries, enforce security and row-level access, maintain chart/dashboard definitions, and support other features.

The metadata model is implemented using SQLAlchemy ORM models in the Superset codebase. The relationships between these entities (for example, a chart belonging to a dataset, which belongs to a database) govern how users interact with data in Superset.

[Top](#top)

## How does Superset handle data lineage in complex data pipelines
Apache Superset, as of its latest releases, does **not natively provide comprehensive data lineage** capabilities. Superset is primarily focused on **data visualization and exploration**, drawing data directly from connected databases or data warehouses via SQLAlchemy-supported connections.

**How Superset handles lineage today:**
- **Visual SQL Editor:** Users can see and manage the SQL queries that define charts, dashboards, and datasets. This provides some transparency about the immediate data source and transformation logic at the visualization level.
- **Dataset Metadata:** Superset maintains dataset-level metadata such as the SQL query, source table, schema, and database. This allows users to track which database tables or queries are powering a particular chart or dashboard.
- **Change Tracking:** Superset logs some changes through its audit log, but this information is limited to user actions (e.g., modifying a chart or dashboard), not full data flow lineage.
- **Integration with External Tools:** For robust data lineage, organizations commonly integrate Superset with dedicated data catalog or lineage platforms (e.g., Amundsen, DataHub, Collibra) that track data flow through ETL pipelines, warehousing, and consumption layers like Superset.

**Limitations:**
- Superset does **not** track upstream ETL transformations or how data arrived in a particular table/view.
- There is no visualization of lineage from source ingestion through transformation to visualization.
- There are no built-in APIs or visual tools in Superset for lineage graphs across systems.

**Typical Solution:**
To achieve end-to-end data lineage in complex pipelines, organizations:
1. Use **external lineage/catalog tools** to map data movement through ETL jobs, warehouses, and BI tools.
2. Leverage the dataset metadata in Superset (e.g., the SQL queries, table names) to cross-reference back to catalog systems.
3. May develop **custom integrations** to surface summary lineage or catalog links inside Superset dashboards.

**Summary:**  
Superset’s role in data lineage is **limited to documenting the immediate data source and transformation queries used for visualization**. For full pipeline lineage, you must supplement Superset with dedicated data governance or lineage tools.

[Top](#top)

## Can Superset connect to data lakes or distributed file systems
Yes, Apache Superset can connect to data lakes or distributed file systems, provided there is an appropriate SQL-speaking interface available. Superset does not connect directly to storage systems like HDFS, S3, or Azure Data Lake. Instead, it connects to databases or query engines that provide SQL access to those storage systems, such as:

- **Presto/Trino:** Both support querying data in data lakes, including files stored on S3, HDFS, or other distributed file systems. Superset includes native connectors for Presto and Trino.
- **Hive:** Allows SQL queries over data stored in HDFS or similar distributed file systems; Superset can connect to Hive using available drivers.
- **Spark SQL:** Provides SQL queries over distributed file systems like HDFS and S3, and can be connected to Superset.

As long as the data lake or distributed file system is accessible through a supported SQL engine with a compatible DBAPI or SQLAlchemy dialect, Superset can be configured to connect, query, and visualize data from those sources.

[Top](#top)

## What are the advantages of using SQL Lab in Superset
SQL Lab in Apache Superset provides several key advantages:

1. **Interactive SQL Editor**: SQL Lab offers a powerful, web-based SQL editor supporting syntax highlighting, autocompletion, and multi-tabbed queries, making it easy to write and refine SQL statements.

2. **Direct Database Connectivity**: It connects directly to supported databases using SQLAlchemy, allowing users to explore, query, and validate data without leaving the Superset interface.

3. **Schema Exploration**: Users can browse database schemas, tables, and their metadata, which helps in understanding data structure and optimizing queries.

4. **Result Visualization**: Query results can be quickly visualized using Superset’s charting options, enabling immediate data exploration and insight generation.

5. **Query Persistence and History**: SQL Lab saves query history and allows saving queries for future reuse, aiding collaborative work and knowledge transfer within teams.

6. **Parameters and Templates**: Users can leverage Jinja templating to write dynamic queries with variables, which supports parameterization and advanced analytical workflows.

7. **Data Download and Export**: Results from queries can be easily downloaded as CSV or Excel files for further offline analysis or reporting needs.

8. **Query Performance Insights**: SQL Lab displays query execution time and allows monitoring of running queries, enabling performance tuning and resource management.

9. **Role-based Access Control**: Access to SQL Lab can be managed via Superset’s security framework, ensuring only authorized users can run or export sensitive queries.

These capabilities make SQL Lab a versatile tool for data analysts, engineers, and scientists, supporting both ad-hoc analysis and production workflows within Superset.

[Top](#top)

## Can Superset handle data from multiple databases or data sources within the same dashboard
Yes, Apache Superset can handle data from multiple databases or data sources within the same dashboard. Superset supports connecting to a wide range of SQL-speaking databases, and each chart or visualization in a dashboard can be based on a different datasource or database connection. This allows users to mix and display datasets from various backend systems (such as MySQL, PostgreSQL, Snowflake, Redshift, etc.) side-by-side in a single dashboard. However, Superset does not perform cross-database joins natively; each chart queries one datasource, but the overall dashboard can compile visualizations from diverse sources.

[Top](#top)

## Can you share dashboards with other users in Superset
Yes, you can share dashboards with other users in Apache Superset. There are several ways to do this:

1. **Built-in Sharing Link:**  
   Each dashboard in Superset has a unique URL. You can copy this link and share it directly with other users who have access to Superset and the appropriate dataset permissions.

2. **Access Control:**  
   Superset manages access via roles and permissions. You can assign roles to users to control who can view or edit specific dashboards. Only users with proper access rights can view shared dashboards.

3. **Embedded Dashboards:**  
   Superset offers the option to embed dashboards in external applications or web pages using iframe embedding or the "embedded dashboards" feature (if enabled). This allows broader sharing beyond the Superset UI, while still maintaining security controls.

4. **Export and Import:**  
   Dashboards can be exported as JSON files and shared. Other users can then import these files into their Superset instance.

Emailing reports or automated report distribution is not natively available in Superset, but some organizations extend Superset with custom scripts or third-party tools for scheduled sharing. The primary approach remains sharing links within the application and managing access with Superset’s security model.

[Top](#top)

## Can you schedule and automate reports in Superset
Apache Superset provides limited built-in options for scheduling and automating reports. As of now:

- **Alerts & Reports**: Superset supports an Alerts & Reports feature, which allows users to schedule periodic email delivery of charts, dashboards, or SQL query results. This uses a combination of the built-in scheduler and Celery workers.
- **Configuration**: To activate this, Superset must be configured with a proper email backend and background workers (Celery, Redis, etc.). The admin needs to set up the necessary environment variables and enable the `ALERT_REPORTS` feature flag.
- **Limitations**: The feature is basic compared to dedicated reporting tools. Custom formatting and complex reporting workflows may not be directly supported.
- **Alternative Workflows**: For more advanced automations, users often leverage Superset’s REST API or database query engines to extract data, and then use external schedulers (like Airflow, cron jobs, etc.) to handle complex scheduling, distribution, or file exports.

In summary: Yes, you can schedule and automate basic email reports via Alerts & Reports, but for advanced scheduling and automation, integration with external tools may be required.

[Top](#top)

## What are the key components of Superset
The key components of Apache Superset are:

1. **Web Application (Frontend):**  
   React-based user interface enabling users to explore, visualize, and interact with data. It provides dashboards, chart builders, and visualization configuration wizards.

2. **Backend (Flask API):**  
   Python Flask application serving as the backend. Handles user authentication, metadata management, SQL execution, and API endpoints for administering and managing Superset.

3. **SQLAlchemy Database Connector Layer:**  
   Abstracts and manages connections to various SQL-speaking databases using SQLAlchemy and supported database drivers.

4. **Artifact Management (Metadata Database):**  
   Stores configuration for dashboards, charts, data sources, and user roles/permissions in a metadata database (commonly uses SQLite, MySQL, or PostgreSQL).

5. **Celery Worker (Async Tasks):**  
   Handles background jobs, such as scheduled report/email, long-running queries, dashboard refreshes, and cache warming. Requires a message broker (e.g., Redis, RabbitMQ).

6. **Visualization Library:**  
   Uses plugins (mainly built on Apache ECharts, D3.js, and others) to render a wide array of customizable visualizations.

7. **Security & Access Control:**  
   Provides robust RBAC (role-based access control) mechanisms to manage user permissions, authentication providers, and row-level security.

8. **Caching Layer:**  
   Integrates with caching systems (e.g., Redis, Memcached) to accelerate query responses and reduce database load.

9. **SQL Lab:**  
   SQL IDE within Superset for ad hoc querying, allows users to write, run, and save queries as well as preview results.

Each of these components works together to deliver a full-featured, extensible, and scalable data exploration and visualization platform.

[Top](#top)

## What is SQL Lab in Superset
SQL Lab in Apache Superset is an interactive SQL IDE (Integrated Development Environment) within the platform. It allows users to write, execute, and analyze SQL queries directly on connected databases. Key features of SQL Lab include:

- **Schema and Table Browsing**: Users can explore available databases, schemas, and tables to better understand the data structure before querying.
- **Query Editor**: A rich SQL editor with syntax highlighting, auto-completion, and formatting options.
- **Result Visualization**: Query results can be viewed in a data grid, exported to CSV, or used to quickly create charts and dashboards.
- **History and Saved Queries**: Users can view past executed queries, save frequently used queries, and share them with other users.
- **Multi-Database Support**: SQL Lab supports querying across multiple databases and data engines connected to Superset.
- **Asynchronous Execution**: Queries can be executed asynchronously, allowing users to run long or complex queries without blocking their UI session.

SQL Lab is typically used for data exploration, data validation, and as an entry point for creating visualizations based on custom SQL queries.

[Top](#top)

## Can Superset connect to cloud-based data warehouses like Amazon Redshift or Google BigQuery
Yes, Apache Superset can connect to cloud-based data warehouses such as Amazon Redshift and Google BigQuery. Superset uses SQLAlchemy as its database abstraction layer, so as long as there is a supported SQLAlchemy dialect or driver for a database, Superset can connect to it. Both Amazon Redshift and Google BigQuery have official SQLAlchemy connectors. To connect, you need to install the required Python packages for the target database, configure the connection string in Superset, and follow any additional authentication steps required by the cloud provider (such as providing service account credentials for BigQuery or IAM roles for Redshift). After the connection is established, you can explore, visualize, and dashboard data from these warehouses inside Superset.

[Top](#top)

## What is Superset's support for dashboard interactivity and filtering
Apache Superset provides extensive support for interactive dashboards and filtering. Key interactivity features include:

1. **Cross-filtering**: Selecting data points in one chart can filter data displayed in other related charts on the dashboard (cross-filters), enabling intuitive exploration.

2. **Interactive Filter Components**: Superset includes filter box elements such as dropdowns, time range selectors, and radio buttons, which can control multiple charts simultaneously.

3. **Native Filters**: Since version 1.0, Superset supports "native filters," allowing users to add filter controls directly onto dashboards. These filters can be global (affecting all charts) or scoped to specific charts.

4. **Drill-down and Drill-through**: Users can configure charts to allow drilling down into more granular data, or even navigate to separate dashboards with context-specific filters.

5. **Dynamic Controls**: Filter selections can be synchronized, and cascading filters are supported, where the options available in one filter depend on selections made in another.

6. **URL Parameterization**: Dashboard state, including filter selections, can be passed and shared using URL parameters, promoting reproducibility and collaboration.

These features enable users to perform ad-hoc slicing and dicing of datasets, discover insights interactively, and tailor dashboards for diverse audiences without exporting data out of Superset.

[Top](#top)

## What is the purpose of the Superset configuration file
The purpose of the Superset configuration file (usually `superset_config.py`) is to provide a centralized location for customizing and managing the settings of an Apache Superset deployment. This file allows administrators to override default settings and configure key aspects such as:

- **Database connections:** Specify SQLALCHEMY_DATABASE_URI for the metadata database.
- **Authentication and security:** Enable or configure authentication backends, CSRF protection, OAuth, and other security-related parameters.
- **Application behavior:** Set options for feature flags, timeouts, logging levels, allowed origins for CORS, cache configuration, and other runtime behavior.
- **Visual and UI preferences:** Customize branding, theming, and other user interface-related options.
- **Performance tuning:** Configure caching mechanisms, background task queues (Celery), and other parameters that affect performance.

By placing this file in the Python path, Superset loads it at startup, applying any overrides or custom settings before the application runs. This allows for both out-of-the-box operation and extensive customization, depending on deployment needs.

[Top](#top)

## How does Superset handle data caching for queries with dynamic parameters
Superset uses a caching layer to improve query performance, but its behavior can differ for queries with dynamic parameters. Superset’s cache key is computed based on several factors: the SQL query text (as generated by the visualization query context), database engine, database connection, and any parameters (filter values, time ranges, etc.) being passed.

When a user submits a query with dynamic parameters (e.g., time ranges, user-based filters), those parameters are included in the generation of the cache key. This means that if the same base query is run with different parameter values, each unique set of parameter values produces a unique cache key, resulting in separate cache entries. So, Superset will not serve cached results for a query with different parameter values—it only serves a cached result if the parameter set matches a previously cached response.

By default, Superset uses the Flask-Caching extension and can leverage caching backends like Redis or Memcached. Administrators can configure cache expiration policies globally or on a per-chart basis.

In summary:  
- Superset includes dynamic parameter values in the query’s cache key.  
- Queries with different parameters are cached separately.  
- Changing dynamic parameters like filters or temporal values causes Superset to issue a new query (unless an identical parameter set was previously cached).  
- Cache configuration and persistence depend on the backend and TTL policies set by administrators.

[Top](#top)

## What is Superset's support for anomaly detection
Apache Superset does not natively provide built-in anomaly detection algorithms as part of its core features. However, Superset does offer support for time-series analysis and can visualize anomaly detection outputs if the data source or SQL queries provide flagged or scored anomalies.

Key points about anomaly detection support in Superset:

- **Visual Representation**: Superset allows users to display anomaly scores or flags as separate columns or visualization overlays (for example, on time-series line charts).
- **Integration with SQL Queries**: Anomaly detection must be performed upstream (e.g., in the database, with Python on the backend, or through scheduled ETL jobs). Superset visualizes the results via custom SQL queries or table fields.
- **Custom Python Script (Legacy Feature)**: The deprecated "Time Series - Anomaly" visualization allowed for basic anomaly highlighting (e.g., using Prophet/Scipy under specific setups), but this feature is no longer actively supported.
- **Extensions/Plugins**: Some users extend Superset with custom visualization plugins or integrate with external alerting and detection tools, but this requires additional development.

To summarize, anomaly detection is not a core, out-of-the-box feature in Superset. Anomalies must be detected before data reaches Superset, and Superset’s role is to visualize the results using charts, tooltips, or conditional formatting based on how the anomaly data is exposed.

[Top](#top)

## What is the Superset SQL Lab Query History feature
The SQL Lab Query History feature in Apache Superset provides a record of all the SQL queries executed by a user within SQL Lab. It allows users to view, search, and revisit past queries. Each entry in the history includes critical details such as the executed SQL statement, execution time, status (success or failure), database and schema used, user who executed it, timing metrics, and sometimes the result set preview. Users can re-run previous queries, open them to continue editing, or use them as templates for new analyses. This feature enhances productivity by offering traceability, easier debugging, and iterative query development. The Query History can usually be accessed via the 'Query History' tab in SQL Lab.

[Top](#top)

## Can Superset connect to streaming data sources
Superset does not natively support real-time streaming data sources in the sense of ingesting and visualizing continuously updating, event-driven streaming data (such as directly connecting to Kafka or a websocket stream). Superset’s data access model is fundamentally SQL-based, relying on querying supported databases or engines that expose a SQL interface.

However, Superset can visualize near real-time data if:

- The underlying SQL database (e.g., Apache Druid, ClickHouse, Pinot) can ingest data from streaming sources and make the latest data available via SQL queries.
- Superset dashboards are set to auto-refresh at a configured interval (down to a few seconds).

In this architecture, Superset’s role is to query the underlying store—which itself is responsible for ingesting and storing streaming data—at regular intervals. Superset does not act as a streaming consumer nor does it connect directly to streaming brokers. Instead, it relies on streaming-capable databases that provide a SQL layer, and Superset refreshes visualizations by querying that layer.

Common streaming-friendly backends for Superset include Apache Druid, Apache Pinot, and ClickHouse. Direct connection to raw streaming platforms such as Kafka or Kinesis is not supported.

[Top](#top)

## Does Superset support embedding dashboards in other applications
Yes, Apache Superset supports embedding dashboards into other applications. Superset provides an "Embedded Dashboard" feature that allows dashboards to be securely embedded as iframes into external web applications. This feature supports different levels of embedding security, including public (unauthenticated) embedding and authenticated embedding using JSON Web Tokens (JWT). The embedding functionality is designed to ensure secure access to dashboards, and embedding options can be configured by administrators. Additionally, Superset supports embeddable URLs and the ability to control the appearance and available interactions of embedded dashboards through configuration and feature flags.

[Top](#top)

## Can Superset be used for real-time data streaming analytics
Superset is primarily designed for interactive data exploration and visualization on top of SQL-speaking databases. It queries data from databases at the time the user opens a dashboard or chart. Superset does not natively support real-time data streaming analytics in the sense of directly ingesting or processing streaming data (like Apache Kafka, Apache Flink, or streaming pipelines). However, it can visualize near real-time data if your underlying database or data source supports and exposes fresh data.

For real-time dashboards, users typically pair Superset with databases that can handle rapid ingestion and querying of streaming data, such as:

- Apache Druid
- ClickHouse
- Pinot
- TimescaleDB (for time series data)

By refreshing dashboards or charts at short intervals and querying a database that is continuously updated with streaming data, Superset can act as a front-end for near real-time analytics. However, Superset itself relies on scheduled or on-demand querying—it does not have built-in streaming ingestion, processing, or native push updates for live data.

In summary, Superset can be part of a real-time analytics solution if paired with the appropriate data infrastructure, but it is not a streaming analytics engine itself.

[Top](#top)

## What is Apache Superset
Apache Superset is an open-source business intelligence (BI) and data visualization platform. It allows users to explore, analyze, and visualize datasets from a variety of data sources through an intuitive web interface. Superset supports connecting to numerous SQL-speaking databases, building interactive dashboards, and creating a wide range of charts without writing code. It is designed for scalability, making it suitable for deployment in large organizations, and provides features for authentication, role-based access control, and the ability to customize charts and dashboards. Superset is implemented primarily in Python and JavaScript and is maintained by the Apache Software Foundation.

[Top](#top)

## What is a dashboard in Superset
A dashboard in Apache Superset is a collection of visualizations, charts, and other data components arranged on a single screen to provide a comprehensive view of key metrics and insights. It allows users to combine multiple charts that often draw from different datasets, enabling interactive data exploration through filters, drill-downs, and cross-filtering. Dashboards help stakeholders monitor business performance and make data-driven decisions by presenting complex analytics in an easily digestible, customizable format.

[Top](#top)

## What is the role of metadata databases in Superset
In Apache Superset, the metadata database plays a central role by storing the platform’s internal data and configuration. Specifically, it is used to:

- Store Superset objects such as dashboards, charts (visualizations), datasets, saved queries, users, roles, and permissions.
- Track relationships and metadata related to connected data sources (like database connection configuration—not the actual analytical data).
- Store audit logs for user actions such as query execution, dashboard editing, or login events.
- Maintain configuration settings required for Superset to function properly, including feature flags and scheduling information for alerts and reports.
- Serve as the storage for background task statuses (when using Celery asynchronous tasks).

The metadata database does not store the end user’s actual data or query results, only the information that enables Superset to reference, display, and interact with those data sources and artifacts. It is a critical component of any Superset deployment and must be properly configured and backed up to ensure the system’s integrity and reliability. By default, it uses SQLite, but production deployments commonly use PostgreSQL or MySQL.

[Top](#top)

## What are Superset's alerting capabilities
Apache Superset has alerting capabilities through its **Alerts & Reports** feature. This functionality allows users to:

- **Create Alerts**: Set up alerts on individual charts by configuring a SQL query and specifying threshold conditions (for example, "alert me if sales drop below 10,000").
- **Schedule Reports**: Schedule regular email reports containing dashboards or chart snapshots to specific recipients.
- **Notification Channels**: Send alerts and reports via email, and, with appropriate configuration, integrate with Slack, Webhook endpoints, or other channels using supported notification backends.
- **Failure Detection**: Configure alerts to notify users when a scheduled query fails due to data source issues or other errors.
- **Flexible Scheduling**: Use cron-like scheduling to determine when reports are triggered or alerts are evaluated.

Note: Alerting and reporting require that Superset is set up with a backend message broker such as Celery, and a results backend, as they rely on asynchronous tasks.

Superset’s alerting is typically used for:
- Monitoring KPIs and key metrics automatically
- Notifying stakeholders about anomalies or threshold breaches
- Receiving automated snapshots of dashboards and charts

In summary, alerting in Superset enables automated monitoring of data conditions and scheduled reporting, but relies on additional configuration (worker queues, notification setup) for full functionality.

[Top](#top)

## Can Superset connect to NoSQL databases
Out of the box, Apache Superset primarily supports SQL-speaking data sources via SQLAlchemy drivers. NoSQL databases, which do not use SQL, are not natively supported. However, certain NoSQL databases (such as Google BigQuery, Apache Druid, and Apache Pinot) offer SQL-like interfaces or official SQLAlchemy connectors, allowing them to integrate with Superset. For document stores like MongoDB, third-party SQLAlchemy connectors exist (e.g., `mongoalchemy`, `mongodb_sqlalchemy`), but these may have limitations regarding SQL support, stability, and functionality in Superset. For full-fledged support, the NoSQL system must provide a SQL interface and a compatible SQLAlchemy dialect or connector. Custom connectors can also be developed if needed. In summary, direct support is limited, but integration is possible if a SQL interface is available.

[Top](#top)

## Does Superset support cross-database joins in SQL queries
No, Apache Superset does not natively support cross-database joins in SQL queries within its query editor. Superset issues queries directly to the underlying database engine—such as Postgres, MySQL, BigQuery, etc.—and relies on each database's capabilities. Most database engines do not support querying across different databases or database engines in a single SQL statement.

If users need cross-database analysis, they typically have to:

- Use a database that supports federated queries (e.g., Presto/Trino, or some data warehouses like BigQuery, Athena), and configure Superset to connect via a single SQLAlchemy connection to that engine.
- ETL the required data into a single database for analysis.
- Use virtual datasets in Superset with SQLAlchemy models against a database engine that handles federation or cross-database linking.

Superset itself doesn't orchestrate or combine data from multiple databases at query time.

[Top](#top)

## Can you explain the process of connecting a database to Superset
To connect a database to Apache Superset:

1. **Install the Database Driver**:  
   Superset uses SQLAlchemy for database connections, so the appropriate Python DB-API driver must be installed in your Superset environment (for example, `psycopg2` for PostgreSQL or `mysqlclient`/`PyMySQL` for MySQL).

2. **Gather Connection Details**:  
   Obtain the necessary information: database type, hostname, port, username, password, and database name.

3. **Format the SQLAlchemy Connection String**:  
   Construct the SQLAlchemy URL in the appropriate format, for example:  
   - PostgreSQL: `postgresql+psycopg2://user:password@host:port/dbname`
   - MySQL: `mysql+pymysql://user:password@host:port/dbname`

4. **Add the Database in Superset**:  
   - Log into the Superset web UI as an admin user.
   - Navigate to **Data** → **Databases**.
   - Click the **+ Database** button.
   - Enter the **Display Name** for the connection.
   - Paste the SQLAlchemy URI.
   - Optionally, test the connection.

5. **Configure Additional Settings (Optional)**:  
   You can set advanced configurations, such as exposing in SQL Lab, setting async query engines, or adding extra parameters in JSON format.

6. **Save the Connection**:  
   Click **Connect** or **Finish** to add the database.  
   After saving, Superset will introspect the metadata and you can start adding tables for exploration and visualization.

**Common Issues:**  
- Missing or incorrect database drivers.
- Incorrect permissions or network/firewall settings.
- Wrong SQLAlchemy string format.

**Security Note:**  
It's recommended to use environment variables or the Secret Manager for sensitive credentials rather than saving plaintext credentials directly when possible.

[Top](#top)

## What is Superset's data caching mechanism
Superset’s data caching mechanism is designed to improve performance and responsiveness by reducing unnecessary repeated queries to databases. Superset utilizes Flask-Caching, which provides a configurable caching backend (such as Redis or Memcached).

There are two main types of caching in Superset:

1. **Query Results Caching:**  
   When a user runs a SQL query (e.g., through a chart or SQL Lab), Superset can cache the result set. Subsequent identical queries within the cache timeout period will retrieve data from the cache instead of querying the database again. This is governed by the `CACHE_CONFIG` and the `DATA_CACHE_CONFIG` settings in `superset_config.py`. The default backend is in-memory, but production setups typically use external backends like Redis.

2. **Metadata Caching:**  
   Superset can cache metadata (such as table schemas, filter values, and dashboard states) to improve dashboard and chart load times. This is controlled via the `CACHE_DEFAULT_TIMEOUT` and other related settings.

Key concepts:
- **Configurable per-datasource and per-chart:** Caching behavior such as timeout duration and cache backend can be set globally or on specific charts/datasources.
- **Cache Invalidation:** Cached data can be invalidated on demand (e.g., when a dataset is modified) or automatically after the timeout expires.
- **Customizability:** Organizations can write custom cache key generation or control exactly what’s cached through the configuration.

The system helps Superset scale for high concurrent usage and large datasets by minimizing load on back-end databases and making frequent dashboard views much faster.

[Top](#top)

## Can you create drill-down or drill-through reports in Superset
Apache Superset supports basic forms of drill-down and drill-through capabilities, though not as natively or extensively as some other BI tools (like Power BI or Tableau). Here's an overview:

**1. Drill-Down (In-place Exploration):**
- Many visualization types allow users to click and filter data interactively. For example, clicking on a bar in a bar chart or a segment in a pie chart can filter the dashboard or other charts based on that selection.
- You can set up dashboard-level filters and cross-filtering, where interactions with one chart filter data in other charts on the dashboard.
- Visualizations like Treemap or Sunburst support native hierarchical drill-down within the chart.

**2. Drill-Through (Navigation to Related Views):**
- Superset doesn't have a fully integrated "Drill-through to a new report/page" feature out of the box.
- However, you can mimic drill-through behavior by configuring links or actions that pass filter values to other dashboards or explore views using the "Open in new tab" feature, or by adding custom URLs.
- With the URL parameters, you can pass context to other dashboards, enabling a user to jump from a high-level view to a more detailed dashboard with pre-applied filters.

**Workarounds and Enhancements:**
- Advanced use of dashboard filter components and cross-filters can create interactive, exploratory dashboards close to drill-down/through experiences.
- Recent versions have improved cross-filtering support, making interactive exploration smoother.
- For more complex drill-down or drill-through workflows, some organizations use custom Javascript visualization plugins.

**Summary:**  
Superset provides interactive filters and supports cross-filtering, giving users some drill-down capabilities, and with dashboard actions and URL parameters, partial drill-through workflows can be created. However, out-of-the-box, it does not have dedicated "drill-through report" functionality like some enterprise BI tools.

[Top](#top)

## How can you create a new dashboard in Superset
To create a new dashboard in Apache Superset:

1. **Login** to your Superset instance.
2. From the main navigation, go to **Dashboards** > **+ Dashboard** (or **Dashboards** > **Create** > **Dashboard**, depending on version).
3. Enter a **Name** for the dashboard and any optional metadata (owners, tags, etc.).
4. Click **Create**.
5. After creation, you’ll be brought to the dashboard editing interface. Click **Edit Dashboard**.
6. Use the **Add Chart** (or "+" button) to search for and add pre-existing charts to your dashboard, or create new charts directly if needed.
7. Arrange and resize dashboard components using drag-and-drop.
8. Use **Save** or **Save as** to persist your layout and widget selections.

The new dashboard will now be available under the Dashboards list and can be shared or edited further as needed.

[Top](#top)

## What is Superset's SQL Lab Ad-Hoc Editor
Superset's SQL Lab Ad-Hoc Editor is an interactive SQL query interface within Apache Superset that allows users to write, run, and explore SQL queries against connected data sources. It’s designed for exploratory data analysis and data inspection without the need to create permanent saved charts or dashboards.

Key features include:

- Syntax highlighting and autocompletion for writing SQL queries.
- The ability to run and preview query results immediately.
- Visualization options to quickly graph query outputs.
- Saving query snippets for reuse.
- Query history and result downloads (CSV, Excel).
- Leverages database connections set up in Superset to query multiple engines.
- Allows users to share queries with others or copy query links.

SQL Lab is mainly used by analysts, data engineers, or any user who needs to interact directly with raw data before formalizing analyses or creating dashboard-level visualizations.

[Top](#top)

## How can you customize the look and feel of Superset's visualizations and dashboards
Superset’s visualizations and dashboards can be customized extensively through multiple approaches:

**1. Built-in Visualization Controls:**  
Superset provides controls in the Explore view for every chart type. Users can adjust colors, chart types, labels, axis formatting, legend position, tooltips, and other stylistic elements directly in the UI using dropdowns, color pickers, and settings panels.

**2. Custom CSS:**  
Administrators can enable the "Allow CSS Overrides" setting to support custom CSS at the dashboard level. This allows fine-grained customization of dashboard elements including backgrounds, borders, fonts, and more by injecting CSS code directly from the dashboard edit interface.

**3. Dashboard Layouts:**  
Superset’s dashboard builder supports drag-and-drop layout management, letting users arrange charts, headers, markdown widgets, and spacers freely. Sizing, resizing, and placement can be handled visually for custom arrangements and consistent branding.

**4. Theme Configuration:**  
From version 1.4, Superset enables theme customization via configuration files. The `APP_THEME` entry in `superset_config.py` allows overriding default palettes, defining custom color schemes, and setting brand-specific themes for more consistent visual identity.

**5. Custom Visualization Plugins:**  
For advanced needs, Superset supports custom plugins written in JavaScript using the Superset Plugin Chart API. This allows organizations to create new chart types or deeply customize the rendering and interactivity of existing ones.

**6. Markdown and HTML Components:**  
Dashboards support Markdown and HTML widgets, enabling the inclusion of styled text, images, and links to enhance the dashboard’s appearance or convey additional context.

Together, these features let users tailor Superset’s appearance to match organizational branding, improve readability, and align with end-user preferences.

[Top](#top)

## Which programming language is Superset primarily built with
Superset is primarily built with Python. The backend uses the Flask web framework, while the frontend is developed with JavaScript, utilizing React.js.

[Top](#top)

## How does Superset handle data lineage and data governance
Superset does not natively provide full-featured data lineage and data governance functionalities. Its primary purpose is data visualization and dashboard creation, relying on connections to external databases and data warehouses.

**Data lineage:**  
Superset does not track how data flows or transforms from source to dashboard natively. Metadata such as dataset definitions, SQL queries, and charts' underlying queries are stored, but these are not visualized or managed as lineage graphs. Any lineage awareness must be implemented externally, by integrating Superset with data catalog or data governance tools (for example, via integrations with tools like Amundsen or DataHub).

**Data governance:**  
Superset supports basic governance via robust access control at the application level:
- **RBAC (Role-based access control):** You can manage who can access dashboards, charts, datasets, and which actions they can perform.
- **Security features:** You can restrict SQL Lab usage, enforce row-level security (RLS), and restrict access to data sources and metrics.

For comprehensive data governance (data cataloging, quality tracking, data retention policies), you need to use dedicated platforms or extend Superset via API/integrations.

In summary, Superset focuses on access control and auditing at the visualization layer. For end-to-end lineage and data governance, external solutions and integrations are required.

[Top](#top)

## Does Superset support data exploration using natural language queries (NLQ)
As of version 3.0 and later, Apache Superset includes support for data exploration using natural language queries (NLQ). This feature, known as "Explore with NLQ," allows users to type questions in plain English (or other supported languages), and Superset translates those into SQL queries against connected databases. NLQ support depends on enabling the feature and configuring the necessary backends, such as integrating with external NLP services or using the built-in parsing capabilities. The effectiveness of the NLQ feature varies based on the complexity of questions and the metadata available in Superset. Not all database backends are equally supported, and NLQ may require feature flags or specific settings to be activated.

[Top](#top)

## How can you secure Superset
To secure Apache Superset, you should implement the following measures:

1. **Authentication**:  
   - Enable strong authentication methods such as OAuth, LDAP, or integrate with enterprise SSO (Single Sign-On) systems.
   - Avoid using the default admin credentials and ensure all users have strong, unique passwords.
   - Use HTTPS to protect login credentials in transit.

2. **Authorization**:  
   - Configure granular roles and permissions using Superset’s RBAC (Role-Based Access Control) system.
   - Limit access to sensitive data and dashboards by assigning appropriate permissions to each user or group.

3. **Network Security**:  
   - Deploy Superset behind a secure reverse proxy and firewall.
   - Limit public access using security groups or IP allow-lists.
   - Disable unused ports and monitor network traffic for suspicious activity.

4. **Database Security**:  
   - Use database-specific users with limited privileges for Superset’s connections.
   - Never expose your database credentials in plain text outside of secure configuration files.

5. **CSRF/XSS Protection**:  
   - Keep Superset updated, as security patches may include fixes for cross-site scripting (XSS) or cross-site request forgery (CSRF) issues.
   - Enable built-in CSRF protection in Superset’s configuration (`ENABLE_CSRF_PROTECTION = True`).

6. **Secret Management**:  
   - Store sensitive configuration values (like `SECRET_KEY`, database passwords) in environment variables rather than in source-controlled files.
   - Rotate secrets regularly.

7. **Auditing and Logging**:  
   - Enable and monitor logging for user actions and system events.
   - Integrate with centralized logging and monitoring tools for auditing and intrusion detection.

8. **Dependency and Version Management**:  
   - Regularly update Superset and its Python dependencies to patch vulnerabilities.
   - Use tools like `pip-audit` or `safety` to monitor for insecure dependencies.

9. **Backup and Recovery**:  
   - Regularly back up your Superset metadata database.
   - Test recovery procedures to prepare for data loss or security incidents.

10. **Container Security (if using Docker)**:  
    - Use official or verified Superset Docker images.
    - Run containers with minimal privileges and avoid running as root.

In summary, securing Superset requires attention to authentication, authorization, network and database security, regular updates, and monitoring. Always consult the [official documentation](https://superset.apache.org/docs/installation/security) for the latest best practices.

[Top](#top)

## Can you define metrics and dimensions in Superset
In Apache Superset:

- **Metrics** are aggregate numerical values calculated from your data, such as SUM(sales), AVG(price), COUNT(*), MAX(score), etc. Metrics are generally used to quantify or summarize data and are computed at query time according to your chart or table configuration.

- **Dimensions** are categorical fields that are used to segment, group, or filter data. These are typically columns like 'country', 'category', 'date', or 'product type'. Dimensions are usually non-aggregated and form the basis for slicing or breaking down your metrics.

In summary, metrics provide the "what" you want to measure, while dimensions define the context or groups by which you measure those metrics within Superset visualizations and queries.

[Top](#top)

## What is Superset's support for data permissions and data masking
Superset provides robust support for data permissions and some basic capabilities for data masking:

**Data Permissions:**
- Superset uses a Role-Based Access Control (RBAC) system. Permissions can be assigned to Users and Roles, controlling access at a granular level.
- You can restrict access to:
  - Databases: Control which users can see/query which data sources.
  - Datasets: Limit visibility and querying of specific tables/views.
  - Charts and Dashboards: Manage who can view, edit, or share specific dashboards/charts.
- Permissions can also be set for features like SQL Lab access, saved queries, and administrative actions.
- Row Level Security (RLS) policies allow you to define which rows a user can see based on filters, using dynamic criteria (e.g., user, role, custom attributes).

**Data Masking:**
- Superset itself does not directly support data masking (such as obfuscating or tokenizing specific columns) at the application layer.
- However, you can implement data masking using RLS or database views:
  - Use RLS to restrict columns by hiding them or restricting visible rows, but not to mask the contents of a column.
  - For actual masking (e.g., showing masked email addresses), implement it at the source (in the database) via SQL views, database policies, or custom SQL expressions in Superset virtual datasets.
  - Any data masking logic should ideally be handled at the database level to ensure security.

In summary, Superset offers detailed permissions and row-level security, while data masking requires external database logic or creative use of SQL and dataset configurations.

[Top](#top)

## What is a slice in Superset
In Apache Superset, a **slice** is an individual data visualization, such as a chart or graph. It represents a saved query configuration—including the data source, metrics, filters, visualization type, and formatting settings. Slices are reusable components: they can be embedded into one or more dashboards and can be edited or updated independently of those dashboards. In newer Superset terminology, "slice" and "chart" are often used interchangeably, but historically, "slice" referred specifically to these saved visualizations.

[Top](#top)

## What is Superset's support for row-level security (RLS)
Superset supports row-level security (RLS) by allowing administrators to define rules that restrict which rows of data a user can access in a given database table or view. This is achieved through the “Row Level Security” feature:

- RLS rules are managed at the Superset metadata layer, not directly within the source database.
- Rules can be created and associated with either datasets or tables.
- Each rule consists of a filter clause (typically a SQL expression) and can be assigned to one or more roles (Superset roles).
- When a user queries a dataset with an RLS rule, the filter is automatically applied, ensuring users see only the rows they’re permitted to access.
- Superset supports two types of RLS rules: Regular filters (for specific roles or datasets) and Base filters (applied to all queries, unless another rule overrides it).
- RLS is enforced transparently in both the Explore UI and dashboards; users do not need to be aware of it.
- As of the latest versions, RLS works for SQLAlchemy-supported databases.
- RLS does not provide full protection if users have SQL Lab or database-level access, where they can write raw SQL to bypass Superset’s rule enforcement.
- Best practice is to use database’s native RLS features for highly sensitive data, or ensure users only access data via Superset’s abstraction.

In summary, Superset's RLS offers a security feature to filter rows on a per-user or per-role basis at the application level, adding a layer of access control to dashboards and visualizations.

[Top](#top)

## How can you extend Superset's functionality
Superset's functionality can be extended in several ways:

1. **Custom Visualization Plugins**:  
   Superset supports a plugin architecture for visualizations. You can create custom chart plugins using the `@superset-ui` libraries and register them via the Superset Plugin API. This allows you to add new chart types tailored to specific needs.

2. **Custom Database Connectors**:  
   Superset relies on SQLAlchemy for database connections. You can extend support for additional databases by implementing a compatible SQLAlchemy dialect or customizing database engine specs.

3. **Superset REST API**:  
   Superset exposes a RESTful API. You can build external applications, integrate with other platforms, or automate workflows by interacting with Superset via this API.

4. **Custom Security and Authentication**:  
   Superset uses Flask AppBuilder (FAB) for handling security and authentication. You can create custom security manager classes to integrate with third-party authentication providers (e.g., OAuth, LDAP, SAML) or implement custom RBAC logic.

5. **SQL Lab Features**:  
   You can develop and deploy custom macros, templates, and pre-processing hooks to enhance SQL Lab capabilities, such as dynamic query parameters or templating engines.

6. **Override and Extend Frontend**:  
   Superset’s frontend is built with React and can be extended by modifying or replacing React components. You can build custom UI components, dashboards, or themes to match specific branding or workflows.

7. **Custom AppBuilder Views and Extensions**:  
   By leveraging Flask AppBuilder’s extension points, you can add new pages, endpoints, or admin features directly into Superset.

8. **Configuration Overrides**:  
   The `superset_config.py` file allows for extensive customization, including new logging handlers, feature flags, extra Jinja functions, and integration points for third-party services.

9. **Adding Hooks**:  
   Superset emits several signals (e.g., after chart save, before dashboard delete). You can use hooks to trigger custom logic when such events occur.

By leveraging these extensibility points, organizations can customize Superset to fit a wide variety of business and technical requirements.

[Top](#top)

## What is Superset's approach to data caching and cache invalidation
Superset uses a caching layer to improve performance by avoiding repeated expensive queries to the data sources. Its approach to data caching involves:

- **Caching Query Results:** Superset can cache the results of SQL queries and chart computations, reducing load on the backend databases when the same queries or visualizations are requested multiple times.
- **Backend Options:** Superset leverages Flask-Caching as an abstraction layer. Out of the box, it supports various backends like Redis, Memcached, or local memory for storing cache data, which can be configured via the `CACHE_CONFIG` property in `superset_config.py`.
- **Granular Caching:** Caching can be controlled at several levels, including datasource-level caching, chart-level caching, and dashboard-level caching.
- **Automatic Invalidation:** Cache invalidation can occur automatically based on a maximum "timeout" (TTL, time-to-live) that’s set during configuration. When the TTL expires, the cached data is considered stale and will be recomputed on the next request.
- **Manual Invalidation:** Users or administrators can manually trigger cache invalidation. This can be done via the user interface (refresh options in charts or dashboards) or programmatically through the API or CLI commands.
- **Query Uniqueness:** Superset uses a cache key that is generated from the query and its context (including user’s filters and parameters). Any change in the query parameters, user filters, or dataset triggers a new cache key, thus fetching new data.

Cache configuration and invalidation policies need to be balanced depending on data freshness requirements and performance considerations of the deployment.

[Top](#top)

## How can you install Superset
Apache Superset can be installed using several methods, but the most common way is with pip, Python's package installer. Here are the typical steps for installing Superset in a production or development environment:

**1. Set up a Python environment**  
- Superset requires Python 3.8, 3.9, or 3.10.  
- It's recommended to use a virtual environment:
  ```bash
  python3 -m venv superset-venv
  source superset-venv/bin/activate
  ```

**2. Install Apache Superset with pip**  
- Upgrade pip:
  ```bash
  pip install --upgrade pip setuptools wheel
  ```
- Install Superset:
  ```bash
  pip install apache-superset
  ```

**3. Initialize the database**  
- Run the following to set up and initialize the metadata database:
  ```bash
  superset db upgrade
  ```

**4. Create an admin user**  
```bash
superset fab create-admin
```
- You will be prompted to enter credentials for the admin user.

**5. Load example data (optional)**  
```bash
superset load_examples
```

**6. Initialize roles and permissions**  
```bash
superset init
```

**7. Start the Superset web server**  
```bash
superset run -p 8088 --with-threads --reload --debugger
```
- The default port is 8088. You can then access Superset at: `http://localhost:8088`.

**Docker installation**
- For those preferring Docker, Superset provides an official Docker Compose setup. The repository contains a `docker-compose.yml` that can be started with:
  ```bash
  git clone https://github.com/apache/superset.git
  cd superset
  docker-compose -f docker-compose-non-dev.yml up
  ```
- This method is recommended for evaluation or containerized production environments.

**System dependencies**
- Superset requires certain build tools and server dependencies (like Node.js and npm for frontend builds [developers], libpq for PostgreSQL support, etc.), especially for production installations.  
- Refer to the [official documentation](https://superset.apache.org/docs/installation/installing-superset/) for OS-specific pre-requisites.

These are the standard steps to install Apache Superset in most scenarios.

[Top](#top)

## Can you deploy Superset in a distributed environment
Yes, Apache Superset can be deployed in a distributed environment to support scalability, high availability, and better fault tolerance. In a distributed setup, the main components—Superset web server, message queue (such as Celery with Redis or RabbitMQ), and the metadata database (e.g., PostgreSQL or MySQL)—are separated and can be scaled independently.

Key steps to deploying Superset in a distributed environment:

1. **Web Workers**: Run multiple Superset web server instances (using a WSGI server like Gunicorn or uWSGI) behind a load balancer to handle concurrent user requests.

2. **Asynchronous Task Workers**: Deploy multiple Celery workers for handling background jobs such as dashboard and chart caching, report generation, and scheduled email alerts. The task queue backend must be a distributed system like Redis or RabbitMQ.

3. **Metadata Database**: Host the metadata database (PostgreSQL or MySQL) on a robust, dedicated server or use a managed distributed database to ensure data consistency and reliability.

4. **Caching Layer**: Consider adding a distributed caching service (such as Redis or Memcached) to improve performance of dashboard loads and API requests.

5. **Shared File Systems**: If you are using the option for file uploads (like report attachments), mount a shared file system (or use object storage such as AWS S3) accessible to all Superset instances.

6. **Stateless Architecture**: Superset is designed to be stateless, making it suitable for distributed environments and container orchestration platforms like Kubernetes or Docker Swarm.

Recommended practices include using infrastructure-as-code tools, defining health checks, and monitoring/logging all distributed components. Properly configured, this setup allows Superset to serve large numbers of users and heavy analytics workloads efficiently.

[Top](#top)

## Does Superset support multi-tenancy
Superset does not support true multi-tenancy out of the box in the sense of completely isolated tenants with data, metadata, and user information fully separated at the application/database level. However, there are several ways to approximate multi-tenancy:

1. **Row-level security (RLS):** Superset supports row-level security filters, which can restrict what data users or groups of users can see within the same tables/datasources.

2. **Role-based access control (RBAC):** Superset allows fine-grained permission assignments by roles. You can define roles for different “tenants,” and control which dashboards, charts, and datasources they can access.

3. **Workspace Segmentation:** By careful organization of dashboards and datasources, and by restricting access to these objects via roles, effective soft multi-tenancy can be achieved.

4. **Separate Superset Deployments:** For hard isolation, it's possible to run separate Superset instances (with separate metadata databases) for each tenant.

5. **No UI/Branding Isolation:** Superset does not provide UI branding or navigation isolation per tenant. All users access the same URL and the same basic interface.

In summary, while Superset lacks built-in, seamless multi-tenancy (like some SaaS products), it enables “soft” multi-tenancy via RLS, RBAC, and organization, but complete isolation or white-labeling requires custom architecture or multiple deployments.

[Top](#top)

## What are some common security best practices for deploying Superset
Some key security best practices for deploying Apache Superset include:

1. **Authentication & Authorization**:  
   - Integrate with enterprise authentication systems such as LDAP, OAuth, OIDC, or SAML.
   - Restrict public access; do not expose Superset to the open internet without proper authentication.
   - Assign roles and permissions using Superset’s RBAC (Role-Based Access Control). Grant only the necessary permissions to users and groups.

2. **Use HTTPS**:  
   - Always run Superset behind HTTPS to encrypt data in transit, especially authentication credentials and queries.

3. **Secret Management**:  
   - Secure all sensitive configuration values (such as `SECRET_KEY` and database passwords) using environment variables or secret management tools; never hardcode them.
   - Use strong, unique secrets.

4. **Restrict Database Access**:  
   - Use database accounts with the least privileges needed for Superset’s functionality.
   - Avoid granting Superset users superuser or data-modifying privileges if not necessary.

5. **Limit Data Exposure**:  
   - Use dataset and dashboard permissions to control data visibility.
   - Leverage row-level security (RLS) filters where appropriate.

6. **Upgrade and Patch**:  
   - Always use the latest stable Superset version and promptly apply patches to address known vulnerabilities.
   - Keep dependencies and underlying system packages up-to-date.

7. **Network Security**:  
   - Deploy Superset behind a secure reverse proxy or load balancer.
   - Use firewalls and security groups to block unwanted traffic.
   - Restrict Superset’s access only to required networks and databases.

8. **Content Security Policy (CSP)**:  
   - Set CSP headers to reduce the risk of XSS (Cross-Site Scripting) attacks.

9. **Session Management**:  
   - Configure session timeouts and consider using secure cookies (`SESSION_COOKIE_SECURE`).
   - Enable CSRF (Cross-Site Request Forgery) protection.

10. **Logging and Monitoring**:  
    - Enable audit logging to track key actions.
    - Monitor logs for suspicious activity.

11. **Disable Guest and Anonymous Access**:  
    - Remove or restrict the default ‘public’ or ‘gamma’ roles if not needed.

Applying these best practices helps ensure a secure Superset deployment and protects sensitive data from breaches and misuse.

[Top](#top)

## What is Superset's support for time-zone conversions in visualizations
Superset provides robust support for time-zone handling in visualizations. By default, Superset interprets and displays timestamps using the server time zone unless specified otherwise. However, users can customize this behavior in several ways:

1. **Database Time Zone Awareness:**  
   If the underlying database stores timestamps with explicit time zone information (e.g., as TIMESTAMP WITH TIME ZONE), Superset can read and use these timezone-aware records.

2. **User-Level Time Zone Selection:**  
   Superset allows users to specify their preferred display time zone in their profile settings ("Settings" → "Profile" → "Time zone"). Once set, Superset automatically converts all time fields in charts and tables to this time zone when rendering visualizations.

3. **Default Time Zone for All Users:**  
   Administrators can configure a default time zone for the deployment via environment variables (e.g., `SUPERSET_DEFAULT_TIMEZONE`), which applies if users have not set a personal preference.

4. **dttm Columns Standardization:**  
   Within datasets, you can designate which column represents datetime (dttm). Superset leverages this to apply the appropriate conversions and controls, including shifting based on user or global settings.

5. **Frontend Conversion and Formatting:**  
   When rendering chart axes, tooltips, or table columns with date/time data, Superset uses the browser or specified time zone to localize and format datetimes, providing an accurate context.

6. **SQL Expressions for Custom Conversions:**  
   If more complex or custom conversions are needed, you can use SQL expressions directly in the dataset or chart to convert between time zones explicitly before visualization.

7. **Limitations:**  
   - Superset does not automatically detect ambiguous or naive datetimes; consistent storage in UTC at the database level is generally recommended.
   - Some database engines or custom SQL queries may require explicit time zone handling within the query itself.

In summary, Superset supports flexible time-zone conversions through user and system preferences, column configuration, and SQL logic, ensuring visualizations reflect the intended temporal context.

[Top](#top)

## How can you monitor the performance of Superset
Superset performance can be monitored using several approaches:

1. **Application Logs**: Superset produces detailed logs that provide insights on slow queries, errors, and overall request handling. These logs can be tailed, parsed, or sent to log management systems like ELK or Splunk for further analysis.

2. **Built-in Metrics with StatsD**: Superset has built-in support to emit performance and usage metrics (such as request latency, cache hits, query execution time, etc.) to StatsD. This allows integration with monitoring solutions like Graphite, Datadog, or Prometheus (using exporters).

3. **Database Monitoring**: Since Superset is heavily reliant on its metadata database (e.g., PostgreSQL, MySQL) and the datasource database engines it queries, monitoring database performance (using tools like pg_stat_statements, slow logs, or APM) can help identify bottlenecks with metadata or data queries.

4. **Celery Task Monitoring**: For deployments that use asynchronous query execution or dashboard refreshes, Celery is used. The health and throughput of Celery workers can be monitored via Flower or Prometheus exporters.

5. **System-Level Metrics**: Monitoring system resources such as CPU, memory, disk, and network utilization on the Superset host is crucial. Tools like top, htop, and container-monitoring solutions (if running via Docker/Kubernetes) provide these insights.

6. **Application Performance Monitoring Tools**: Integrating Superset with APM tools (like New Relic, Datadog APM, or Prometheus with Flask middleware) can help in tracking request paths, response times, error rates, and performance regressions.

7. **Superset’s own SQL Lab Query History**: The SQL Lab interface shows recent queries and their performance, allowing users and admins to review query duration and identify slow-performing queries.

Monitoring should be done across all the components in the Superset architecture (web server, Celery workers, metadata DB, source DBs) for a holistic view of system health and performance.

[Top](#top)

## What is Superset's support for data exploration on streaming data sources
Apache Superset’s support for data exploration on streaming data sources is limited and primarily depends on the underlying database or data engine capabilities. Superset itself is a data visualization and exploration platform that connects to external databases via SQLAlchemy connectors. It does not natively ingest or process streaming data; instead, it queries whatever data is present in the connected source at query time.

For exploring near-real-time or streaming data, Superset can visualize data from databases that support streaming data queries or very frequent data refresh:

- Superset can connect to databases and engines designed for streaming or real-time data analysis, such as Apache Druid, Apache Pinot, ClickHouse, or Materialize. These engines are capable of ingesting streaming data and serving up-to-date results through SQL interfaces.
- Superset dashboards and charts can be configured with automatic refresh intervals, allowing users to see updated metrics at a regular cadence (e.g., every few seconds or minutes), giving a pseudo-real-time exploration experience.
- Superset does not itself manage data ingestion or stream processing pipelines. Integration and optimal performance for streaming use cases rely on how well the connected database handles high-velocity inserts and low-latency queries.
- Limitations: Superset cannot natively display continuously updating data points without user-triggered or timed refreshes, and its query execution and visualization pipeline are batch-oriented at the point a user loads or schedules chart updates.

In summary, Superset’s capability for exploring streaming data is fundamentally dependent on the capability of the connected real-time databases, combined with its dashboard refresh features, rather than any built-in stream processing or continuous query execution.

[Top](#top)

## Does Superset support geospatial data visualization
Yes, Apache Superset supports geospatial data visualization. It includes several built-in chart types for visualizing geospatial data, such as **deck.gl** charts (e.g., Point, Polygon, Scatter, Arc layers), and MapBox-based visualizations. Superset can render data with latitude and longitude fields, allowing users to display locations, clusters, heatmaps, and paths on interactive maps. It also supports GeoJSON data and custom map tile providers, offering flexibility for advanced geospatial analysis.

[Top](#top)

## Can you integrate Superset with other BI tools or data platforms
Superset is primarily designed as a standalone open-source business intelligence (BI) and data visualization tool focused on visual exploration of data. Its integration capabilities are oriented around the following:

**1. Data Source Integration:**  
Superset connects to a wide variety of SQL-speaking databases (e.g., PostgreSQL, MySQL, Snowflake, BigQuery, Redshift, Druid, Trino, etc.) using SQLAlchemy dialects. This allows it to pull data directly from most common data platforms used in analytics.

**2. Embedding and Sharing:**  
Superset offers the ability to embed dashboards and charts via iframe or as React components, making it possible to surface visualizations within other platforms, portals, or custom web applications.

**3. REST API:**  
Superset exposes a REST API that allows programmatic control over many operations, such as creating and updating charts, dashboards, and datasets. This supports integration with other BI tools or orchestration platforms, though it's not always as full-featured as APIs from major proprietary BI tools.

**4. Export/Import:**  
It supports exporting dashboards, charts, and datasets as JSON files. These can be imported into another Superset instance or processed by other tools.

**5. SSO and User Management Integration:**  
Superset can integrate with authentication methods such as LDAP, OAuth, SAML, or custom authentication through Flask AppBuilder, allowing for single sign-on (SSO) integration with enterprise identity providers.

**6. Limitations:**  
Superset is not designed to be a backend "engine" for other BI tools like Tableau, Power BI, or Qlik. It does not serve as a common metadata layer or query engine across BI platforms. Native "live" interoperability with other BI tool UIs is limited.

**Summary:**  
Superset can serve as an analytics and visualization layer over diverse data platforms, and can be embedded or automated to some degree. For deeper, seamless integration with other BI platforms, customization or middleware would be required. Most commonly, organizations use Superset alongside other BI tools rather than integrating them directly.

[Top](#top)

## Can you integrate Superset with external authentication systems
Yes, Superset can be integrated with external authentication systems. Superset leverages Flask AppBuilder (FAB) for its security and authentication framework, which supports a variety of authentication backends. Common integration scenarios include:

- **LDAP / Active Directory:** Superset can authenticate users against LDAP or Active Directory using configuration options in `superset_config.py`.
- **OAuth / OpenID Connect:** Superset can use OAuth2 or OpenID Connect providers (such as Google, Okta, Azure AD, Auth0) by enabling the respective authentication backends and providing client configuration.
- **SAML:** Superset supports SAML authentication via the `auth_saml` backend.
- **Custom Authentication:** You can implement custom authentication logic by extending Flask AppBuilder’s security manager.

These integrations allow for single sign-on (SSO) and centralized user management. User roles and permissions can also be mapped and managed using these external systems. All authentication-related configuration is typically defined in `superset_config.py`.

[Top](#top)

## What is Druid in the context of Superset
In the context of Apache Superset, Druid refers to Apache Druid, a high-performance, real-time analytics database designed for fast slice-and-dice analytics on large datasets. Superset natively supports Druid as a data source, allowing users to connect to Druid clusters, explore datasets, and build interactive dashboards on data stored in Druid. This integration enables Superset users to leverage Druid's strengths in handling time-series and high-cardinality data, powering fast and flexible visual analytics directly from Druid tables.

[Top](#top)

## What is Superset's support for user-defined functions (UDFs)
Apache Superset itself does not directly support the creation or execution of user-defined functions (UDFs) within its interface. Superset acts as a data visualization and exploration layer that connects to underlying databases. Any UDFs must be defined and created in those databases themselves (e.g., PostgreSQL, MySQL, BigQuery, etc.). Once the UDF exists within the connected database, it can be referenced and used in SQL queries within Superset’s SQL Lab, charts, or dashboards, provided the database’s SQL dialect and Superset’s SQL editor support it.

Key points regarding UDFs in Superset:

- Superset does not have native UI or features to define, upload, or manage UDFs.
- Superset can use UDFs that are already created in the underlying database during query execution.
- The availability and behavior of UDFs depend entirely on the capabilities of the database backend.
- Users need sufficient privileges in the database to create or use UDFs.
- When writing queries in SQL Lab or configuring datasets, users are free to invoke these database-side UDFs as part of their SQL.

In summary, UDF support in Superset relies on the connected data source and is not managed by Superset itself.

[Top](#top)

## Does Superset support data lineage across multiple dashboards and slices
Out of the box, Apache Superset does **not** provide native data lineage features across multiple dashboards and slices (charts). Superset’s core functionality centers on data exploration, visualization, and dashboarding, rather than tracking the downstream or upstream flow of data between datasets, charts, or dashboards.

Key points:

- Superset does not display how changes in a dataset (table or query) might impact multiple charts or dashboards.
- There is no inbuilt data lineage graph, audit trail of query dependencies, or mapping of relationships between datasets, charts (slices), and dashboards.
- Some metadata is available in the Superset metadata database (for example, which slices use which datasets, or which dashboards include which slices), but this is not exposed as a true lineage feature.
- For advanced data lineage tracking, integration may be needed with external tools such as **Amundsen**, **DataHub**, or **Marquez**, which specialize in metadata and lineage for data platforms.
- Recently, there have been some metadata improvements (such as dataset-level information) but they are not presented as full lineage features.

In summary, if comprehensive cross-dashboard or cross-slice lineage is needed, it requires third-party tooling or custom development on top of Superset’s metadata.

[Top](#top)

## What are some ways to optimize query performance in Superset
Some ways to optimize query performance in Apache Superset:

1. **Leverage Caching**:  
   - Enable and properly configure Superset’s built-in query and chart caching (Memcached, Redis, or filesystem). This prevents redundant database queries and speeds up dashboard loads.

2. **Optimize Database Queries**:  
   - Ensure the underlying database is indexed correctly to speed up filtering and joining.
   - Use efficient SQL queries—avoid SELECT *, limit the number of rows returned, and use aggregation wisely.
   - Offload computation-heavy logic to materialized views, database views, or table calculations in the database.

3. **Limit Row Fetch**:  
   - Use Superset’s row limit feature to cap the number of rows brought back per query, especially for exploratory visualizations.
   - Apply filters at the dashboard or chart level to restrict large data pulls.

4. **Tune Data Sources**:  
   - Use a dedicated OLAP database or data warehouse (e.g., Druid, ClickHouse, BigQuery, Redshift) for analytics workloads.
   - Partition large tables and/or shard them to distribute query pressure.

5. **Aggregate Data**:  
   - Create summary tables or pre-aggregated tables to minimize computation during dashboard rendering.
   - Use time granularity functions (e.g., day, week, month) to aggregate data before visualization.

6. **Scheduled Reports and Asynchronous Queries**:  
   - Use background jobs or report schedules to precompute heavy dashboards.
   - Enable asynchronous SQL execution, letting the browser poll for long-running queries.

7. **Disable Unused Visual Features**:  
   - Turn off chart data retrieval or limit features (like “group by” with too many categories) that result in heavy queries.

8. **Resource Allocation**:  
   - Increase worker counts (e.g., for Gunicorn), tune Celery workers when using asynchronous mode.
   - Ensure sufficient resources and connectivity between Superset and the backend database.

9. **Monitor and Audit**:  
   - Use Superset’s built-in query log to identify slow SQL and optimize as needed.
   - Gather database EXPLAIN plans for expensive queries.

By combining these approaches, it’s possible to significantly improve query and dashboard performance in Superset.

[Top](#top)

## What is Superset's support for time-series data analysis
Apache Superset offers robust support for time-series data analysis. It provides a variety of visualization options specifically designed for time-series, such as time-series line charts, area charts, bar charts, mixed time-series charts, and heatmaps. Users can aggregate, zoom, and compare time-based data easily.

Core features supporting time-series analysis in Superset include:

- **Time Granularity:** Users can select different time grains, such as seconds, minutes, hours, days, weeks, or months, directly from the chart configuration UI.
- **Time Filters:** Superset supports powerful time filtering options, including predefined periods (e.g., last week, last month, last year), rolling windows, and custom date ranges.
- **Time Shifting:** The "Time comparison" feature enables creating comparison lines or bars (e.g., this year vs. previous year) within a single chart.
- **Rolling Window Calculations:** Users can apply rolling functions (like moving averages and cumulative sum) to smooth or further analyze trends in the time-series.
- **Advanced SQL Support:** For more complex analysis, users can write custom SQL queries or use the SQL Lab to directly manipulate time-series data.
- **Annotations and Events:** Charts can be enriched with annotations or event markers to highlight specific moments, such as releases or outages, directly on time-series graphs.
- **Timezone Awareness:** Superset handles timezone conversions and allows visualizations to show times in user-specified timezones, ensuring clarity across audiences.

All these features make Superset well-suited for interactive and advanced analysis of time-based trends and patterns in data.

[Top](#top)

## Can Superset integrate with external data catalog systems
Yes, Apache Superset can integrate with external data catalog systems, but this capability depends on the specific catalog and the integration approach:

- There is **no built-in, out-of-the-box deep integration** with popular data catalogs like Apache Atlas, Amundsen, or DataHub as part of Superset’s core features as of 2024.
- Superset exposes a REST API, which can be used to programmatically register, update, or synchronize database connections, datasets, and dashboards, enabling partial automation with cataloging systems.
- Some data catalog platforms (for example, Amundsen and DataHub) have community-contributed plugins or scripts that can **extract metadata from Superset** (such as dashboards, charts, and data sources) and ingest it into the catalog, supporting data lineage and discovery.
- Conversely, Superset does not directly "consume" metadata from catalogs to auto-generate datasets or dashboards, but you can manually register datasets from cataloged sources.
- Custom integration is possible by developing scripts or connectors that bridge catalog APIs and Superset’s APIs to synchronize data assets and metadata.

In summary, while Superset does not natively provide comprehensive, plug-and-play data catalog integration, it offers enough API access and extensibility to enable custom or semi-automated integration workflows with external data catalog systems.

[Top](#top)

## How does Superset handle large datasets
Apache Superset is designed to interact with large datasets efficiently by taking advantage of the underlying data warehouse or database rather than loading data into its own memory. Here’s how Superset handles large datasets:

1. **Queries Delegated to Database:** Superset sends SQL queries directly to the connected database, which does the heavy lifting—filtering, aggregating, and limiting data—before returning results to Superset.

2. **Result Limiting:** By default, Superset enforces row limits on queries (configurable via the interface or administrator settings) to prevent accidentally pulling large datasets into memory or frontend visualizations.

3. **Asynchronous Queries:** Superset supports asynchronous query execution, especially when paired with Celery, allowing long-running queries on large datasets to run in the background without blocking the user interface.

4. **Query Caching:** Superset implements result caching (using Redis or similar backends), so repeated queries on large data don’t hit the database every time, speeding up performance and reducing load.

5. **Distributed/Scalable Architecture:** Superset can be deployed in a scalable fashion with multiple worker processes and a distributed backend, which helps in managing higher query loads and larger datasets.

6. **Big Data Backends Supported:** Superset natively integrates with big data engines like Presto, Trino, Druid, and others that are specifically optimized for massive datasets and interactive analytics.

7. **Sampling for Visualizations:** Users can configure sample sizes for visualizations to display a representative subset, reducing the workload when exploring billions of rows.

8. **Custom SQL and Filtering:** Users can write custom SQL queries or use filter controls to narrow down data before visualization, ensuring only the necessary subset of data is processed.

By leveraging these mechanisms, Superset enables interactive exploration and dashboarding even on very large datasets, while avoiding memory overload and performance issues on the Superset server itself.

[Top](#top)

## What is Superset's support for data access logging and auditing
Apache Superset provides data access logging and auditing capabilities primarily through its integration with Flask AppBuilder and underlying logging frameworks.

- **Action Logging**: Superset logs user actions such as logins, query executions, dashboard accesses, and CRUD operations on objects (like charts and dashboards). These logs are stored in the database's `logs` table by default, recording details such as user, action, timestamp, and object accessed.

- **SQL Query Auditing**: All SQL queries run through Superset—whether from SQL Lab, Dashboards, or Explore—can be logged. The queries and metadata are stored in the database’s `query` table. This supports audit trails by associating queries with user identities and timestamps.

- **Configurable Logging**: Superset uses Python's standard logging system. You can configure log output (format, level, destination), redirect logs to external log aggregators (e.g., Splunk, ELK) or syslog, and define custom loggers for more granular auditing.

- **Extensibility**: For deeper audit needs, Superset allows adding custom logging logic via plugins or directly in your Flask AppBuilder hooks/methods.

- **Compliance**: These features can aid with compliance (SOC 2, GDPR, etc) by enabling review of who accessed or modified sensitive data, when, and how.

In summary, Superset offers built-in data access logging, with query-level detail, user identification, and extensible logging systems suitable for most audit requirements.

[Top](#top)

## How does Superset handle data security and access control
Superset handles data security and access control through several mechanisms:

**Authentication:** Superset supports multiple authentication backends, including database authentication, OAuth, LDAP, OpenID, and integration with SSO providers. This determines who can log in to the platform.

**Authorization and Roles:** Superset uses a role-based access control (RBAC) system. Permissions are grouped into roles (e.g., Admin, Gamma, Alpha), defining what actions a user can perform—such as creating dashboards, accessing SQL Lab, or modifying databases. Custom roles and fine-grained permissions can be configured in the Security section.

**Object-level Access Control:** Superset can restrict access to specific data sources. Administrators can grant or revoke permissions to datasets, dashboards, charts, and saved queries via roles. Row Level Security (RLS) rules can be applied to datasets to filter data based on user or group attributes, ensuring users see only the appropriate data segments.

**Database Credentials:** Superset connects to underlying databases with service accounts or personal credentials (in some configurations). It’s recommended to use least-privilege database users for production deployments, to limit what Superset can access or modify.

**Audit Logging:** Superset maintains audit logs of key actions (viewing datasets, running queries, editing dashboards), which assists in monitoring user activities and identifying security incidents.

**Custom Security Managers:** Advanced deployments can implement a custom Security Manager class to extend or modify Superset’s default security behavior, integrating with enterprise IAM, ABAC, or external policy engines.

Security best practices also recommend ensuring encryption of data in transit (HTTPS), securing backend database connections, and keeping Superset and dependencies up to date with security patches.

[Top](#top)

## What is Superset's integration with Apache Airflow
Apache Superset and Apache Airflow are two distinct but often complementary components in the modern data stack. Superset is a modern data exploration and visualization platform, while Airflow is an orchestration tool for scheduling and managing workflows such as ETL pipelines.

**Integration Points:**

1. **Data Readiness and Orchestration:**
   - Airflow is typically used to orchestrate and automate the data pipelines that load and transform data in data warehouses (such as PostgreSQL, BigQuery, Snowflake) that Superset will ultimately connect to and visualize.
   - Airflow ensures the data is up-to-date and ready for analytics, while Superset is used to explore and present data after those pipelines complete.

2. **Triggering Dashboards or Reports:**
   - There is no out-of-the-box, native integration that allows Airflow to directly trigger or interact with Superset dashboards or schedules. However, it’s a common practice to use Airflow tasks to validate or update data, and then notify users (e.g., via email or Slack) when new dashboards in Superset are ready for viewing.

3. **API-based Workflows:**
   - Superset exposes a REST API (and a legacy CLI) that can be used to programmatically refresh data sources, clear cache, export/import dashboards, or even trigger chart or dashboard data refreshes.
   - Airflow can use its PythonOperator or other operator plugins to call Superset’s APIs as a step in a DAG, creating loose coupling between the orchestration and visualization layers.

4. **Embedding and Linking:**
   - Some teams design Airflow DAGs to output HTML links to Superset dashboards as part of notification tasks, making it easy for data consumers to immediately access visualizations after pipeline completion.

5. **Authentication & Security:**
   - Both support OAuth and can be integrated with enterprise authentication systems, if organizations want a cohesive security posture.

**Summary:**
Superset and Airflow do not have a direct, built-in integration, but they are commonly used together in the data lifecycle. Integration typically happens at the orchestration level (ensuring data readiness) and optionally through Superset’s REST API for automating certain Superset operations as part of data workflows managed by Airflow.

[Top](#top)

## What is Superset's support for data storytelling and annotations
Apache Superset offers features that support data storytelling and visual context through several capabilities:

**Annotations and Annotation Layers:**  
Superset provides the ability to add annotation layers to visualizations, particularly time-series charts (such as line, area, or bar charts with a time axis). Users can create annotation layers in two main forms:
  - **Event Annotations:** Mark significant events or milestones directly on a chart (for example, product launches, outages, policy changes), helping viewers correlate these events with changes in the data.
  - **Region Annotations:** Highlight specific time ranges (shaded regions) to emphasize periods of interest (for instance, marketing campaigns or financial quarters).

These annotation layers can be managed, edited, and reused across multiple dashboards and charts, enhancing narrative context across different analyses.

**Chart and Dashboard Markdown:**  
Superset allows text elements based on Markdown to be embedded within dashboards. This supports richer storytelling by enabling users to:
  - Add headings, explanations, data interpretation, or instructional content alongside visualizations.
  - Build step-by-step stories or highlight key findings.

**Chart Titles and Descriptions:**  
Each visualization can include detailed descriptive text—titles, subtitles, and longer descriptions—helping viewers understand what is being displayed, the significance, and the data's context.

**Limitations:**  
Superset’s storytelling features focus on contextual enhancements rather than highly guided, interactive stories (such as those possible in tools like Tableau Story Points or Power BI bookmarks). As of now, it does not natively support branching narratives, page-by-page guided walkthroughs, or fine-grained interaction-driven storytelling. However, through thoughtful use of annotation layers, markdown widgets, and dashboard layouts, a rich narrative can still be constructed for business users.

In summary, Superset supports data storytelling through annotation layers, markdown text, and descriptive elements, enabling users to add both visual and written context to their data analyses.

[Top](#top)

## Does Superset provide data lineage tracking
No, Apache Superset does not natively provide comprehensive data lineage tracking. Superset is primarily a data exploration and visualization platform, focusing on query creation, dashboards, and interactive visualizations. While users can see the SQL queries used for charts and dashboards, as well as metadata about datasources and metrics, it does not offer built-in features to trace end-to-end data flow, transformations, or dependencies across datasets and pipelines.

For detailed data lineage, integration with external tools such as Amundsen, DataHub, or OpenLineage is necessary. These integrations can provide lineage information alongside Superset, but this functionality is not part of Superset's core feature set.

[Top](#top)

## Can Superset handle real-time data processing and visualization
Apache Superset is not fundamentally designed for real-time data processing or streaming analytics in the way that frameworks like Apache Kafka or Apache Flink are. Superset functions as a data exploration and visualization platform that queries data from underlying databases, data warehouses, or other supported data sources.

Superset can, however, display frequently updated or near real-time data, depending on how the underlying data source and queries are configured. For example, if the underlying database is being updated in real time, and Superset dashboards or charts are set to auto-refresh at short intervals (minimum 10 seconds as per Superset's default configuration), it can provide a near real-time visualization experience. The actual "freshness" of displayed data depends on:

- The real-time capabilities of the data source (database, Druid, etc.)
- The configuration of Superset's chart and dashboard refresh intervals
- The efficiency and latency of the queries being executed

Superset does not ingest or process streaming data itself. It is limited to querying the latest available data from sources that may be updated in real time. For true streaming analytics with low-latency, continuous processing, Superset is not a replacement for real-time stream processing systems but can work in conjunction with them if those systems write the processed data to a supported database.

In summary:  
- Superset is not a real-time data processing platform.  
- It can visualize near real-time data if the datasource supports it and dashboards are set to refresh frequently.  
- Superset’s “realtime” experience is only as good as the underlying data source’s update frequency and the query latency.  
- Superset does not connect directly to streaming sources like Kafka topics; it works through databases that may contain real-time data.

[Top](#top)

## Can you integrate Superset with version control systems
Out of the box, Apache Superset does **not provide native integration with version control systems** like Git. Superset stores most of its metadata—including dashboards, charts, and dataset definitions—in its own backend database, rather than as flat files that can be directly tracked by standard version control.

However, some approaches can help achieve version control over Superset assets:

- **Export/import functionality:** Superset supports exporting dashboards, charts, and datasets as YAML or JSON files through the UI or CLI (`superset export-dashboards`, `superset import-dashboards`). These exported files can be checked into a version control system, reviewed, and managed as code.

- **Automated CI/CD:** Teams may script the export and import process, enabling dashboards as code workflows, where changes are reviewed in PRs and imported automatically into environments.

- **Database as Source of Truth:** For some users, using database migrations (with tools like Alembic or Flyway) to manage the underlying metadata database can be a form of version control, though it's less granular and less user-friendly.

- **Third-party tools and plugins:** Some open-source and commercial tools exist to further automate the synchronization of Superset objects with Git repositories.

In summary: Superset doesn’t natively “sync” with Git, but version control can be achieved using export/import and automation workflows.

[Top](#top)

## How does Superset differ from other BI tools
Apache Superset differs from other BI tools in several key areas:

**Open Source and Extensibility:**  
Superset is fully open source under the Apache 2.0 license, which allows organizations to modify, extend, and integrate it deeply according to their needs, unlike many proprietary BI solutions.

**Cloud-Native and Modern Architecture:**  
It’s designed as a cloud-native, web-based application, allowing for easy horizontal scaling and containerization (e.g., with Kubernetes). This contrasts with some legacy BI tools requiring heavier, monolithic server installations.

**SQL-First Approach:**  
Superset heavily emphasizes a “SQL Lab” experience, providing robust capabilities for exploring data with direct SQL, superior for SQL-savvy analysts. Some BI tools abstract SQL away or limit direct database querying without additional connectors.

**Database Support:**  
Superset supports a wide array of SQL-speaking databases by leveraging SQLAlchemy, including cloud data warehouses (BigQuery, Snowflake, Redshift), traditional RDBMS (Postgres, MySQL), and others. This is in contrast to some tools that have limited connector ecosystems.

**Visualization and Dashboarding:**  
Superset offers a broad selection of built-in visualization types out of the box, and its plugin architecture makes it straightforward to add custom visualizations. While other tools may have more polished or extensive libraries, Superset balances flexibility and rapid development.

**Granular Security and RBAC:**  
It supports advanced role-based access control (RBAC) at the dataset, dashboard, and even row/column level. This matches enterprise BI tools and exceeds the capabilities of lighter-weight options.

**No-code and Low-code Options:**  
While it shines with SQL, Superset also features no-code/low-code exploration capabilities, letting less technical users slice, dice, and visualize datasets (though some proprietary tools offer more WYSIWYG, drag-and-drop depth).

**Deployment Flexibility and Cost:**  
Because it’s open source, Superset incurs no licensing fees and can be customized as needed. This makes it attractive versus tools like Tableau, Power BI, or Looker that require paid licenses or subscriptions.

**Community and Ecosystem:**  
Superset has a large and active open-source community, which fosters rapid innovation and support. Proprietary BI tools may have more comprehensive professional support, but open development leads to quicker adoption of new features.

In summary, Superset distinguishes itself through a modern, open source, SQL-first architecture, broad database compatibility, extensibility, and flexibility, often favored by organizations already invested in cloud-native or open-source stacks.

[Top](#top)

## How can you create a new slice in Superset
To create a new slice (visualization) in Apache Superset:

1. **Select Dataset:**  
   Navigate to "Charts" in the main menu and click the **+ Chart** button. Choose the desired dataset from the dropdown menu. This dataset will serve as the source for your slice.

2. **Choose Visualization Type:**  
   After selecting the dataset, you are presented with a list of visualization types (e.g., bar chart, pie chart, table). Pick the one that fits your analytical need.

3. **Configure the Chart:**  
   Use the chart editor panel to configure your visualization:
   - **Metrics:** Define the aggregation (e.g., SUM, AVG) and column to be visualized.
   - **Dimensions/Group by:** Choose columns to group the metric(s).
   - **Filters:** Add filters to limit your dataset.
   - **Time range:** Specify the temporal scope (if applicable).
   - **Customize Appearance:** Adjust options like colors, labels, axes, sort order, etc.

4. **Run Query and Preview:**  
   Click **Run** or **Update Chart** to execute the query and preview the visualization based on your configuration.

5. **Save the Slice:**  
   When satisfied, click **Save**. You’ll be prompted to enter a name for your slice. You can also add a description, tags, and optionally, assign it to an existing or new dashboard.

The saved "slice" appears in the "Charts" list and can be added to dashboards for further exploration or sharing.

[Top](#top)
